{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jM0FAhXNysbQ",
        "outputId": "00cfd229-33fe-47a4-eb20-d5ae93f19649"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coefficients (beta) using gradient descent: [2.19999993 0.60000002]\n",
            "Residuals (epsilon) using gradient descent: [-0.79999995  0.60000003  1.00000001 -0.60000001 -0.20000003]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "def linear_regression_gradient_descent(X, y, learning_rate=0.01, num_iterations=1000):\n",
        "    # Add a column of ones to the feature matrix for the intercept term\n",
        "    X = np.column_stack((np.ones_like(X), X))\n",
        "\n",
        "    # Initialize coefficients with zeros\n",
        "    beta = np.zeros(X.shape[1])\n",
        "\n",
        "    # Perform gradient descent\n",
        "    for _ in range(num_iterations):\n",
        "        # Calculate predicted values\n",
        "        y_pred = X @ beta\n",
        "\n",
        "        # Calculate the gradient of the cost function\n",
        "        gradient = -2 * X.T @ (y - y_pred)\n",
        "\n",
        "        # Update coefficients using gradient descent\n",
        "        beta -= learning_rate * gradient\n",
        "\n",
        "    return beta\n",
        "\n",
        "def get_residuals_gradient_descent(X, y, beta):\n",
        "    # Add a column of ones to the feature matrix for the intercept term\n",
        "    X = np.column_stack((np.ones_like(X), X))\n",
        "\n",
        "    # Calculate the predicted values using the obtained coefficients\n",
        "    y_pred = X @ beta\n",
        "\n",
        "    # Calculate the residuals (epsilon) as the difference between observed and predicted values\n",
        "    residuals = y - y_pred\n",
        "\n",
        "    return residuals\n",
        "\n",
        "X = np.array([[1], [2], [3], [4], [5]])\n",
        "y = np.array([2, 4, 5, 4, 5])\n",
        "\n",
        "# Performing linear regression with gradient descent\n",
        "coefficients_gd = linear_regression_gradient_descent(X, y)\n",
        "\n",
        "# Getting residuals\n",
        "residuals_gd = get_residuals_gradient_descent(X, y, coefficients_gd)\n",
        "\n",
        "# Print the coefficients and residuals\n",
        "print(\"Coefficients (beta) using gradient descent:\", coefficients_gd)\n",
        "print(\"Residuals (epsilon) using gradient descent:\", residuals_gd)\n",
        "\n"
      ]
    }
  ]
}